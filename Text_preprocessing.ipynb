{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWH7tCfKsBOO5CWTbNxrfb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravinnd3/Generative-AI-Full-Course/blob/main/Text_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2IFNuUIUUaGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "tlWMXg42U-JX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install tqdm\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "\n",
        "# Example usage: create a progress bar for a loop\n",
        "for i in tqdm(range(100), desc=\"Processing items\"):\n",
        "    time.sleep(0.05) # Simulate some work"
      ],
      "metadata": {
        "id": "42nIjktHqJfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Download latest version\n",
        "dataset_path = kagglehub.dataset_download(\"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")\n",
        "\n",
        "destination_path = \"/content/\"\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "os.makedirs(destination_path, exist_ok=True)\n",
        "\n",
        "# Copy the contents of the downloaded dataset to the destination path\n",
        "# We use shell command for simplicity, you could also use shutil.copytree\n",
        "!cp -r \"{dataset_path}/.\" \"{destination_path}/\"\n",
        "\n",
        "print(f\"Dataset copied to: {destination_path}\")\n",
        "\n",
        "# List files in the destination directory to confi"
      ],
      "metadata": {
        "id": "a3qR9LPvU09X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/IMDB Dataset.csv')\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "VT0ljmjMVDI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'][3]"
      ],
      "metadata": {
        "id": "WfV6TCX2VSGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].str.lower()"
      ],
      "metadata": {
        "id": "LswwBLRXWG2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def remove_html_tags(text):\n",
        "  pattern = re.compile('<.*?>')\n",
        "  return pattern.sub(r'', text)"
      ],
      "metadata": {
        "id": "YAVHk0haWNza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].apply(remove_html_tags)"
      ],
      "metadata": {
        "id": "yKN31WVHkm3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'][3]\n"
      ],
      "metadata": {
        "id": "UJc5zLzFkrQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove URL"
      ],
      "metadata": {
        "id": "x0NpxTFzk7EC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_url(text):\n",
        "  pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "  return pattern.sub(r'', text)"
      ],
      "metadata": {
        "id": "TP1_VjYuk2kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].apply(remove_url)"
      ],
      "metadata": {
        "id": "oR71mX6nlHTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Punctuation Handling"
      ],
      "metadata": {
        "id": "wc17ZG5clZ0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string,time"
      ],
      "metadata": {
        "id": "6r7W66fplNxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string.punctuation"
      ],
      "metadata": {
        "id": "6a3XlreXld6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exclude = string.punctuation"
      ],
      "metadata": {
        "id": "yinZzDLflgGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def remove_punctuation(text):\n",
        "#   for char in exclude:\n",
        "#     text = text.replace(char,'')\n",
        "#   return text\n",
        "\n",
        "# another way to remove punctuation which takes less time\n",
        "\n",
        "def remove_punctuation(text):\n",
        "  return text.translate(str.maketrans('', '', exclude))"
      ],
      "metadata": {
        "id": "X935g9oelpg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].apply(remove_punctuation)"
      ],
      "metadata": {
        "id": "kqErYjh2lxwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat conversion handle"
      ],
      "metadata": {
        "id": "TXwx-iRFmdrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_words = {\n",
        "    'AFAIK':'As Far As I Know',\n",
        "    'AFK':'Away From Keyboard',\n",
        "    'ASAP':'As Soon As Possible'\n",
        "}\n",
        "\n",
        "\n",
        "{\n",
        "    \"FYI\": \"For Your Information\",\n",
        "    \"ASAP\": \"As Soon As Possible\",\n",
        "    \"BRB\": \"Be Right Back\",\n",
        "    \"BTW\": \"By The Way\",\n",
        "    \"OMG\": \"Oh My God\",\n",
        "    \"IMO\": \"In My Opinion\",\n",
        "    \"LOL\": \"Laugh Out Loud\",\n",
        "    \"TTYL\": \"Talk To You Later\",\n",
        "    \"GTG\": \"Got To Go\",\n",
        "    \"TTYT\": \"Talk To You Tomorrow\",\n",
        "    \"IDK\": \"I Don't Know\",\n",
        "    \"TMI\": \"Too Much Information\",\n",
        "    \"IMHO\": \"In My Humble Opinion\",\n",
        "    \"ICYMI\": \"In Case You Missed It\",\n",
        "    \"AFAIK\": \"As Far As I Know\",\n",
        "    \"BTW\": \"By The Way\",\n",
        "    \"FAQ\": \"Frequently Asked Questions\",\n",
        "    \"TGIF\": \"Thank God It's Friday\",\n",
        "    \"FYA\": \"For Your Action\",\n",
        "    \"ICYMI\": \"In Case You Missed It\",\n",
        "}"
      ],
      "metadata": {
        "id": "Tv8EOg_Ql1qM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_conversion(text):\n",
        "    new_text = []\n",
        "    for w in text.split():\n",
        "        if w.upper() in chat_words:\n",
        "            new_text.append(chat_words[w.upper()])\n",
        "        else:\n",
        "            new_text.append(w)\n",
        "    return \" \".join(new_text)"
      ],
      "metadata": {
        "id": "bUnMpJ26m01R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].apply(chat_conversion)"
      ],
      "metadata": {
        "id": "cKPTzvA2m-K3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'][6]"
      ],
      "metadata": {
        "id": "AITAR5V1nC2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Incorrect text handling"
      ],
      "metadata": {
        "id": "xHzs07dsnNXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "SkMVxq2WnHup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect_text = 'ceertain conditionas duriing seveal ggenerations aree moodified in the saame maner.'\n",
        "\n",
        "textBlb = TextBlob(incorrect_text)\n",
        "\n",
        "textBlb.correct().string"
      ],
      "metadata": {
        "id": "QQ2YtV2VnRop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df['review'] = df['review'].apply(lambda x: str(TextBlob(x).correct()))"
      ],
      "metadata": {
        "id": "R5OlehLDnWe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stopwords"
      ],
      "metadata": {
        "id": "g_u5WiFXnflY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "eg2npv6Enbuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words('english')"
      ],
      "metadata": {
        "id": "KD2GC61pnkXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text):\n",
        "    new_text = []\n",
        "\n",
        "    for word in text.split():\n",
        "        if word in stopwords.words('english'):\n",
        "            new_text.append('')\n",
        "        else:\n",
        "            new_text.append(word)\n",
        "    x = new_text[:]\n",
        "    new_text.clear()\n",
        "    return \" \".join(x)"
      ],
      "metadata": {
        "id": "Zp2ZGJeLnnNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_stopwords('probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it\\'s not preachy or boring. it just never gets old, despite my having seen it some 15 or more times')"
      ],
      "metadata": {
        "id": "2sy6Vjjgnyfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].apply(remove_stopwords)"
      ],
      "metadata": {
        "id": "mU7P8Pwdn1wO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove emoji Handle"
      ],
      "metadata": {
        "id": "Wr9Q8aJOogKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)"
      ],
      "metadata": {
        "id": "PYglZsnbn-oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_emoji(\"Loved the movie. It was ðŸ˜˜ðŸ˜˜\")"
      ],
      "metadata": {
        "id": "mhhRlFRDonED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "id": "EuYtHs-7ormO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import emoji\n",
        "print(emoji.demojize('Python is ðŸ”¥'))"
      ],
      "metadata": {
        "id": "1XlCZv4Rovp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(emoji.demojize('Loved the movie. It was ðŸ˜˜'))"
      ],
      "metadata": {
        "id": "EM6tnDcCo2gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "2HRFbEByrPN0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Using the split function"
      ],
      "metadata": {
        "id": "CU8JpKxiudTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# word tokenization\n",
        "sent1 = 'I am going to delhi'\n",
        "sent1.split()"
      ],
      "metadata": {
        "id": "q04qviKrrO-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sentence tokenization\n",
        "sent2 = 'I am going to delhi. I will stay there for 3 days. Let\\'s hope the trip to be great'\n",
        "sent2.split('.')"
      ],
      "metadata": {
        "id": "O_nxlVmGrO7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uY_guMpCrO4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Regular Expression"
      ],
      "metadata": {
        "id": "PAL_X4gnuiUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "sent3 = 'I am going to delhi!'\n",
        "tokens = re.findall(\"[\\w']+\", sent3)\n",
        "tokens"
      ],
      "metadata": {
        "id": "zyyKAKgwrOuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. NLTK"
      ],
      "metadata": {
        "id": "oVLLr60SuxDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "QvV8Q4kprOqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent1 = 'I am going to visit delhi!'\n",
        "word_tokenize(sent1)"
      ],
      "metadata": {
        "id": "7CetkIzRu0tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent5 = 'I have a Ph.D in A.I'\n",
        "sent6 = \"We're here to help! mail us at nks@gmail.com\"\n",
        "sent7 = 'A 5km ride cost $10.50'\n",
        "\n",
        "word_tokenize(sent5)"
      ],
      "metadata": {
        "id": "uDk16ym9u30K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(sent6)"
      ],
      "metadata": {
        "id": "ezo2FB5tvPhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(sent7)"
      ],
      "metadata": {
        "id": "d6phRg7CvSOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Spacy (good)"
      ],
      "metadata": {
        "id": "agNPBCpUvbgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "2lpEKiOwvUXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = nlp(sent5)\n",
        "doc2 = nlp(sent6)\n",
        "doc3 = nlp(sent7)\n",
        "doc4 = nlp(sent1)"
      ],
      "metadata": {
        "id": "hJDrXEx_vfGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc4 = nlp(sent1)\n",
        "doc4"
      ],
      "metadata": {
        "id": "whht98tpvhvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc4:\n",
        "    print(token)"
      ],
      "metadata": {
        "id": "ru3DraCcvkW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_HJYvSXivpqu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}